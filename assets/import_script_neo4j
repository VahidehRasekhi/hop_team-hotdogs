-- hopteam db

CREATE CONSTRAINT ON (p:Provider) ASSERT p.from_npi IS UNIQUE;
CREATE CONSTRAINT ON (h:Hospital) ASSERT h.to_npi IS UNIQUE;
CREATE CONSTRAINT ON (t:Taxonomy) ASSERT t.taxonomy_code_provider IS UNIQUE;

:auto USING PERIODIC COMMIT
LOAD CSV WITH HEADERS
FROM 'file:///full_refs.csv' AS line
WITH line

MERGE (p:Provider {npi: line.from_npi,
                   name: COALESCE(line.name, "Full Name Missing")})
MERGE (h:Hospital {npi: line.to_npi,
                   organization: line.organization_hospital})
MERGE (t:Taxonomy {taxonomy_code: line.taxonomy_code_provider,
                   classification: line.classification_provider,
                   specialization: COALESCE(line.specialization_provider, "None")})

CREATE (p)-[:REFERRED_TO {referral_id: toInteger(line.referral_id),
                          patient_count: toInteger(line.patient_count),
                          transaction_count: toInteger(line.transaction_count),
                          avg_day_wait: toFloat(line.average_day_wait),
                          std_day_wait: toFloat(line.std_day_wait)}]->(h)
CREATE (p)-[:SPECIALIZES_IN]->(t)

-- hospteam db

CREATE CONSTRAINT ON (p:Provider) ASSERT p.from_npi IS UNIQUE;
CREATE CONSTRAINT ON (h:Hospital) ASSERT h.to_npi IS UNIQUE;
CREATE CONSTRAINT ON (t:Taxonomy) ASSERT t.taxonomy_code_provider IS UNIQUE;

:auto USING PERIODIC COMMIT
LOAD CSV WITH HEADERS
FROM 'file:///hosp_geo.csv' AS line
WITH line

MERGE (p:Provider {npi: line.from_npi,
                   name: COALESCE(line.name, "Full Name Missing"),
                   address: line.address_provider})
MERGE (h:Hospital {npi: line.to_npi,
                   organization: line.organization_hospital,
                   address: line.address_hospital})
MERGE (t:Taxonomy {taxonomy_code: line.taxonomy_code_provider,
                   classification: line.classification_provider,
                   specialization: COALESCE(line.specialization_provider, "None")})

CREATE (p)-[:REFERRED_TO {referral_id: toInteger(line.referral_id),
                          patient_count: toInteger(line.patient_count),
                          transaction_count: toInteger(line.transaction_count),
                          avg_day_wait: toFloat(line.average_day_wait),
                          std_day_wait: toFloat(line.std_day_wait),
                          distance_miles: toInteger(line.distance_miles)}]->(h)
CREATE (p)-[:SPECIALIZES_IN]->(t)

-- preparing to apply the algorithm

CALL gds.graph.create(
'hospteam',
'*',
{
REFERRED_TO: {
orientation: 'UNDIRECTED',
aggregation: 'SUM'
}
},
{
relationshipProperties: 'patient_count'
}
)


-- applying the algorithm

CALL gds.louvain.stream('hospteam', { relationshipWeightProperty: 'patient_count' })
YIELD nodeId, communityId
RETURN gds.util.asNode(nodeId).npi AS npi, gds.util.asNode(nodeId).name AS name, gds.util.asNode(nodeId).organization AS organization, communityId
ORDER BY organization ASC

-- update hospteam with community nodes and PART_OF relationship
CREATE CONSTRAINT ON (c:Community) ASSERT c.id IS UNIQUE;

:auto USING PERIODIC COMMIT
LOAD CSV WITH HEADERS
FROM 'file:///hosp_simple_communities_trimmed.csv' AS line
WITH line

MERGE (c:Community {id: line.communityId});

-- update hospteam with communityId properties and Community nodes
LOAD CSV WITH HEADERS
FROM 'file:///hosp_simple_coms.csv' AS line

MERGE (n:Hospital {npi: toString(toInteger(line.npi))})
ON MATCH SET n.communityId = line.communityId;

LOAD CSV WITH HEADERS
FROM 'file:///prov_simple_coms.csv' AS line

MERGE (n:Provider {npi: toString(toInteger(line.npi))})
ON MATCH SET n.communityId = line.communityId;

-- create the PART_OF relationships

MATCH
  (h:Hospital),
  (c:Community)
WHERE h.communityId = c.communityId
CREATE (h)-[r:PART_OF]->(c)
RETURN h, c

MATCH
  (p:Provider),
  (c:Community)
WHERE p.communityId = c.communityId
CREATE (p)-[r:PART_OF]->(c)
RETURN p, c;
