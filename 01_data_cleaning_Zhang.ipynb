{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d713cd3",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bba8c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from tqdm.notebook import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e9ba9b",
   "metadata": {},
   "source": [
    "### Columns to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b469b7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nppes = pd.read_csv('data/NPPES_Data_Dissemination_February_2022/npidata_pfile_20050523-20220213_FileHeader.csv')\n",
    "nppes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee9362fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to keep\n",
    "referral_from_cols = ['referral_id', 'from_npi']\n",
    "referral_to_cols = ['referral_id', 'to_npi']\n",
    "referrals_cols = ['referral_id',\n",
    "             'patient_count', \n",
    "             'transaction_count', \n",
    "             'average_day_wait',\n",
    "             'std_day_wait']\n",
    "profile_cols = ['NPI',\n",
    "               'Entity Type Code',\n",
    "                'Provider Organization Name (Legal Business Name)',\n",
    "                'Provider Last Name (Legal Name)',\n",
    "                'Provider First Name',\n",
    "                'Provider Middle Name', \n",
    "                'Provider Name Prefix Text',\n",
    "                'Provider Name Suffix Text',\n",
    "                'Provider Credential Text',\n",
    "                'Provider First Line Business Practice Location Address',\n",
    "                'Provider Second Line Business Practice Location Address',\n",
    "                'Provider Business Practice Location Address City Name',\n",
    "                'Provider Business Practice Location Address State Name',\n",
    "                'Provider Business Practice Location Address Postal Code'\n",
    "               ]\n",
    "taxonomy_code_cols = [col for col in nppes.columns if 'Healthcare Provider Taxonomy Code' in col ]\n",
    "taxonomy_switch_cols = [col for col in nppes.columns if 'Healthcare Provider Primary Taxonomy Switch' in col]\n",
    "taxonomy_cols = ['Code', 'Classification']\n",
    "zip_cbsa_cols = ['zip', 'cbsa', 'usps_zip_pref_city','usps_zip_pref_state']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b912b833",
   "metadata": {},
   "source": [
    "### Write hop teaming tables to sqlite3 db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6903e890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be14944e358142cc8c4e1ba4942d3021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a reference_id and write hop_teaming_2018 csv to three tables in hop_teaming db\n",
    "db = sqlite3.connect('data/hopteam.sqlite')\n",
    "for chunk in tqdm(pd.read_csv('data/DocGraph_Hop_Teaming_2018_Commercial/DocGraph_Hop_Teaming_2018.csv', chunksize = 10000)):\n",
    "    # create a unique referral_id for each referal\n",
    "    chunk = chunk.reset_index().rename(columns = {'index':'referral_id'}) \n",
    "    # select columns to keep and write tables to db\n",
    "    chunk.loc[:,referral_from_cols].to_sql('referral_from', db, if_exists = 'append', index = False) \n",
    "    chunk.loc[:,referral_to_cols].to_sql('referral_to', db, if_exists = 'append', index = False)\n",
    "    chunk.loc[:,referrals_cols].to_sql('referrals', db, if_exists = 'append', index = False)\n",
    "    db.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c577e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect('data/hopteam.sqlite')\n",
    "db.execute('CREATE INDEX from_npi ON hop_teaming(from_npi)')\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796c4cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect('data/hopteam.sqlite')\n",
    "tqdm(db.execute('CREATE INDEX to_npi ON hop_teaming(to_npi)'))\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65c953c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5578e8ff5f14a95bbdae7e515a7ebed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "db = sqlite3.connect('data/hopteam.sqlite')\n",
    "tqdm(db.execute('CREATE INDEX transaction_count ON hop_teaming(transaction_count)'))\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25817a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect('data/hopteam.sqlite')\n",
    "db.execute('CREATE INDEX average_day_wait ON hop_teaming(average_day_wait)')\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b40cdab",
   "metadata": {},
   "source": [
    "### Write NPPES table to sqlite3 db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d948e613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get taxonomy code for each npi and select 15 columns NPPES table to write into the db\n",
    "db = sqlite3.connect('data/hopteam.sqlite')\n",
    "for chunk in tqdm(pd.read_csv('data/NPPES_Data_Dissemination_February_2022/npidata_pfile_20050523-20220213.csv', chunksize=10000)):\n",
    "    # drop NaN for NPI and Zip Code columns\n",
    "    chunk.dropna(subset= ['NPI','Provider Business Practice Location Address Postal Code'], inplace = True)\n",
    "    # melt columns of taxonomy codes\n",
    "    taxonomy_code = chunk.loc[:, ['NPI'] +taxonomy_code_cols]\n",
    "    taxonomy_code = pd.melt(taxonomy_code, id_vars = 'NPI', value_vars = taxonomy_code_cols)\n",
    "    taxonomy_code['match_num']=taxonomy_code['variable'].str.extractall('(\\d+)').unstack()\n",
    "    taxonomy_code = taxonomy_code.rename(columns={'value':'taxonomy_code'})\n",
    "    # melt columns of taxonomy switchs\n",
    "    taxonomy_switch = chunk.loc[:, ['NPI']+taxonomy_switch_cols]\n",
    "    taxonomy_switch = pd.melt(taxonomy_switch, id_vars = 'NPI', value_vars = taxonomy_switch_cols)\n",
    "    taxonomy_switch = taxonomy_switch[taxonomy_switch['value']=='Y']\n",
    "    taxonomy_switch['match_num'] = taxonomy_switch['variable'].str.extractall('(\\d+)').unstack()\n",
    "    # inner join the taxonomy codes table with taxonomy switch table and other profile columns\n",
    "    chunk = (pd.merge(taxonomy_code, taxonomy_switch, how = 'inner', on = ['NPI', 'match_num']).\n",
    "     drop(columns=['variable_x','variable_y', 'match_num','value'])).merge(df.loc[:,profile_cols], on ='NPI')\n",
    "    # extract 5-digit zip codes and assign them to the Business Practice Zip Code column\n",
    "    zip_codes = chunk['Provider Business Practice Location Address Postal Code'].astype(int).astype(str)\n",
    "    correct_zip_code = []\n",
    "    for zip_code in zip_codes:\n",
    "        if len(zip_code) < 5:\n",
    "            correct_zip_code.append(zip_code.zfill(5))\n",
    "        elif len(zip_code) == 5:\n",
    "            correct_zip_code.append(zip_code)\n",
    "        elif len(zip_code) < 9:\n",
    "            correct_zip_code.append(zip_code.zfill(9)[:5])\n",
    "        else :\n",
    "            correct_zip_code.append(zip_code[:5])\n",
    "    chunk['Provider Business Practice Location Address Postal Code']=correct_zip_code\n",
    "    # change the column names to lower cases and replace space with underscore\n",
    "    chunk.columns = [x.lower().replace(' ', '_') for x in chunk.columns]\n",
    "    # write table to db\n",
    "    chunk.to_sql('profile', db, if_exists = 'append', index = False)\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0389ed13",
   "metadata": {},
   "source": [
    "### Write CBSA table to sqlite3 db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c296f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.37 s, sys: 17.6 ms, total: 5.39 s\n",
      "Wall time: 5.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# write zip_cbsa table to db\n",
    "with sqlite3.connect('data/hopteam.sqlite') as db:\n",
    "    chunk = pd.read_excel('data/NPPES_Data_Dissemination_February_2022/ZIP_CBSA_122021.xlsx')\n",
    "    # select and rename 4 columns\n",
    "    chunk = chunk.loc[:,zip_cbsa_cols]\n",
    "    chunk = chunk.rename(columns={'usps_zip_pref_city':'city', 'usps_zip_pref_state':'state'})\n",
    "    # zfill zip to 5 digits\n",
    "    correct_zip_code = []\n",
    "    for zip_code in chunk['zip'].astype(str):\n",
    "        if len(zip_code) <5:\n",
    "            correct_zip_code.append(zip_code.zfill(5))\n",
    "        else:\n",
    "            correct_zip_code.append(zip_code)\n",
    "    chunk['zip'] = correct_zip_code\n",
    "    chunk.to_sql('zip_cbsa', db, if_exists = 'append', index = False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b5a549",
   "metadata": {},
   "source": [
    "### Write Taxonomy table to sqlite3 db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc6a8f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d916664504a74bd8925235d03db749a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# write taxonomy table to db\n",
    "with sqlite3.connect('data/hopteam.sqlite') as db:\n",
    "    for chunk in tqdm(pd.read_csv('data/NPPES_Data_Dissemination_February_2022/nucc_taxonomy_220.csv', chunksize = 10000)):\n",
    "        # select Code and Classification columns\n",
    "        chunk = chunk.loc[:,taxonomy_cols]\n",
    "        # change the columns to lower case\n",
    "        chunk.columns = [x.lower() for x in chunk.columns]\n",
    "        # write the table to db\n",
    "        chunk.to_sql('taxonomy', db, if_exists = 'append', index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117d6c8c",
   "metadata": {},
   "source": [
    "### SQL queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "925bfb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip</th>\n",
       "      <th>cbsa</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00683</td>\n",
       "      <td>41900</td>\n",
       "      <td>SAN GERMAN</td>\n",
       "      <td>PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00683</td>\n",
       "      <td>32420</td>\n",
       "      <td>SAN GERMAN</td>\n",
       "      <td>PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00923</td>\n",
       "      <td>41980</td>\n",
       "      <td>SAN JUAN</td>\n",
       "      <td>PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01010</td>\n",
       "      <td>44140</td>\n",
       "      <td>BRIMFIELD</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01010</td>\n",
       "      <td>49340</td>\n",
       "      <td>BRIMFIELD</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     zip   cbsa        city state\n",
       "0  00683  41900  SAN GERMAN    PR\n",
       "1  00683  32420  SAN GERMAN    PR\n",
       "2  00923  41980    SAN JUAN    PR\n",
       "3  01010  44140   BRIMFIELD    MA\n",
       "4  01010  49340   BRIMFIELD    MA"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT * \n",
    "FROM zip_cbsa\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "with sqlite3.connect('data/hopteam.sqlite') as db:\n",
    "    ref_sqlite = pd.read_sql(query, db)\n",
    "ref_sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6403883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM hop_teaming\n",
    "WHERE transaction_count >= 50\n",
    "    AND average_day_wait <50\n",
    "    AND from_npi IN (SELECT npi FROM nppes WHERE entity_type_code = 1.0)\n",
    "    AND to_npi IN (SELECT npi FROM nppes WHERE entity_type_code = 2.0 AND provider_business_practice_location_address_city_name='NASHVILLE')\n",
    "--LIMIT 5\n",
    "\"\"\"\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM profile\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "with sqlite3.connect('data/hopteam.sqlite') as db:\n",
    "    ref_sqlite = pd.read_sql(query, db) \n",
    "ref_sqlite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c41fb65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>referral_from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>referral_to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>referrals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>profile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>taxonomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zip_cbsa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name\n",
       "0  referral_from\n",
       "1    referral_to\n",
       "2      referrals\n",
       "3        profile\n",
       "4       taxonomy\n",
       "5       zip_cbsa"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display tables in a sqlite db\n",
    "query = \"\"\"\n",
    "SELECT name FROM sqlite_schema\n",
    "WHERE type = 'table' AND name NOT LIKE 'sqlite_%';\n",
    "\"\"\"\n",
    "with sqlite3.connect('data/hopteam.sqlite') as db:\n",
    "    ref_sqlite = pd.read_sql(query, db)\n",
    "ref_sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2996f875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table dropped... \n"
     ]
    }
   ],
   "source": [
    "# # drop a table from sqlite db\n",
    "# db = sqlite3.connect('data/hopteam.sqlite')\n",
    "\n",
    "# #Creating a cursor object using the cursor() method\n",
    "# cursor = db.cursor()\n",
    "\n",
    "# #Doping EMPLOYEE table if already exists\n",
    "# cursor.execute(\"DROP TABLE zip_cbsa\")\n",
    "# print(\"Table dropped... \")\n",
    "\n",
    "# #Commit your changes in the database\n",
    "# db.commit()\n",
    "\n",
    "# #Closing the connection\n",
    "# db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc2fdf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ccda12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905d1da2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da449d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
